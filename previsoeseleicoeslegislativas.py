# -*- coding: utf-8 -*-
"""PrevisoesEleicoesLegislativas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-1Qe-XJFp0gp-ZxM-c0Lyz_h1qtReCnH
"""

import pandas as pd # é o nosso excel dentro do código, serve para manipular tabelas
from sklearn.ensemble import RandomForestRegressor #sklearn é a biblioteca de AI
from sklearn.pipeline import Pipeline # o gestor que organiza as tarefas a fazer
from sklearn.compose import ColumnTransformer # transformar as colunas de texto em colunas numéricas
from sklearn.preprocessing import OneHotEncoder # converte o texto em nº
from sklearn.metrics import mean_absolute_error # calcular o erro do modelo criado

df = pd.read_csv('dados_eleicoes.csv') # carregar dados, ler o ficheiro

dados_treino = df[df['Ano'] < 2025].copy() # Dados de 2019, 2022, 2024
dados_teste = df[df['Ano'] == 2025].copy() # Dados de 2025 (O Teste)

#print(dados_teino)
#print(dados_teste)

X = [ 'Ano','Distrito', 'Partido', '%_Votos_Anteriores (LAG)', 'Governo', 'Inflacao_Anual', 'Desemprego_Anual', 'Partido_existe','Abstencao' ]

Y = ['%_Votos_Atuais (TARGET)']

X_treino = dados_treino[X] # Pistas do passado
y_treino = dados_treino[Y]   # Respostas do passado (gabarito)
X_novos  = dados_teste[X] # Pistas do futuro (sem respostas ainda)

print(X_treino)

colunas_texto = ['Distrito', 'Partido'] # dizemos quais colunas são numéricas e quais são numericas
colunas_numericas = ['Ano','%_Votos_Anteriores (LAG)', 'Governo', 'Inflacao_Anual', 'Desemprego_Anual', 'Partido_existe', 'Abstencao']

# Criamos então o transformados
processador = ColumnTransformer(
    transformers=[
        # Traduz o texto para binário (0s e 1s)
        ('texto', OneHotEncoder(handle_unknown='ignore'), colunas_texto),
        # Deixa os números passarem sem alteração ('passthrough')
        ('numeros', 'passthrough', colunas_numericas)
    ])

# Na prática :
# A coluna Distrito desaparece.
# Nascem colunas novas: Distrito_Lisboa (valor 1 ou 0) e Distrito_Porto (valor 1 ou 0

modelo = Pipeline(steps=[
    ('processador', processador), # Passo 1: Traduzir dados
    ('cerebro', RandomForestRegressor(n_estimators=100,max_depth=3, random_state=42)) # Passo 2: Pensar
])

# Imagina que reunimos 100 analistas políticos numa sala (n_estimators=100). Cada um olha para uma parte dos dados e dá a sua opinião. A previsão final é a média da opinião de todos. Isso evita erros grosseiros de um analista individual.

print("A treinar a máquina AI...")
modelo.fit(X_treino, y_treino)

previsoes = modelo.predict(X_novos)

dados_teste['Previsão AI'] = previsoes

print(dados_teste)

def calcular_loss(modelo, X_dados, y_real):
    # 1. Obter as previsões do modelo
    y_pred = modelo.predict(X_dados)

    # 2. Calcular o MAE (Loss)
    loss = mean_absolute_error(y_real, y_pred)

    return loss

Y_real = dados_teste['%_Votos_Atuais (TARGET)']
loss = calcular_loss(modelo, X_novos, Y_real)
print(f"Loss: {loss:.2f}")